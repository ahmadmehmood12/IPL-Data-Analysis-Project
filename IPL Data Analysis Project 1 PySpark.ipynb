{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93484693-350c-4196-8349-f45a16a3df2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType,BooleanType,DateType,LongType\n",
    "from pyspark.sql.functions import col, when, sum, avg, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# create session \n",
    "\n",
    "spark = SparkSession.builder.appName(\"IPL Data Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0709d073-9203-4024-aab0-91d85ad71483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_schema = StructType([\n",
    "\n",
    "    StructField(\"MatcH_id\", IntegerType(), True),\n",
    "    StructField(\"Over_id\", IntegerType(), True),\n",
    "    StructField(\"Ball_id\", IntegerType(), True),\n",
    "    StructField(\"Innings_No\", IntegerType(), True),\n",
    "    StructField(\"Team_Batting\", StringType(), True),\n",
    "    StructField(\"Team_Bowling\", StringType(), True),\n",
    "    StructField(\"Striker_Batting_Position\", IntegerType(), True),\n",
    "    StructField(\"Extra_Type\", StringType(), True),\n",
    "    StructField(\"Runs_Scored\", IntegerType(), True),\n",
    "    StructField(\"Extra_Runs\", IntegerType(), True),\n",
    "    StructField(\"Wides\", IntegerType(), True),\n",
    "    StructField(\"Legbyes\", IntegerType(), True),\n",
    "    StructField(\"Byes\", IntegerType(), True),\n",
    "    StructField(\"Noballs\", IntegerType(), True),\n",
    "    StructField(\"Penalty\", IntegerType(), True),\n",
    "    StructField(\"Bowler_Extras\", IntegerType(), True),\n",
    "    StructField(\"Out_type\", StringType(), True),\n",
    "    StructField(\"Caught\", IntegerType(), True),\n",
    "    StructField(\"Bowled\", IntegerType(), True),\n",
    "    StructField(\"Run_out\", IntegerType(), True),\n",
    "    StructField(\"LBW\", IntegerType(), True),\n",
    "    StructField(\"Retired_hurt\", IntegerType(), True),\n",
    "    StructField(\"Stumped\", IntegerType(), True),\n",
    "    StructField(\"caught_and_bowled\", IntegerType(), True),\n",
    "    StructField(\"hit_wicket\", IntegerType(), True ),\n",
    "    StructField(\"ObstructingFeild\", IntegerType(), True),\n",
    "    StructField(\"Bowler_Wicket\", BooleanType(), True),\n",
    "    StructField(\"Match_Date\", DateType(), True),\n",
    "    StructField(\"Season\", IntegerType(), True),\n",
    "    StructField(\"Striker\", IntegerType(), True),\n",
    "    StructField(\"Non_Striker\", IntegerType(), True),\n",
    "    StructField(\"Bowler\", IntegerType(), True),\n",
    "    StructField(\"Player_Out\", IntegerType(), True),\n",
    "    StructField(\"Fielders\", IntegerType(), True),\n",
    "    StructField(\"Striker_match_SK\", IntegerType(), True),\n",
    "    StructField(\"StrikerSK\", IntegerType(), True),\n",
    "    StructField(\"NonStriker_match_SK\", IntegerType(), True),\n",
    "    StructField(\"NONStriker_SK\", IntegerType(), True),\n",
    "    StructField(\"Fielder_match_SK\", IntegerType(), True),\n",
    "    StructField(\"Fielder_SK\", IntegerType(), True),\n",
    "    StructField(\"Bowler_match_SK\", IntegerType(), True),\n",
    "    StructField(\"BOWLER_SK\", IntegerType(), True),\n",
    "    StructField(\"PlayerOut_match_SK\", IntegerType(), True),\n",
    "    StructField(\"BattingTeam_SK\", IntegerType(), True),\n",
    "    StructField(\"BowlingTeam_SK\", IntegerType(), True),\n",
    "    StructField(\"Keeper_Catch\", IntegerType(), True),\n",
    "    StructField(\"Player_out_sk\", IntegerType(), True),\n",
    "    StructField(\"MatchDateSK\", LongType(), True)\n",
    "])\n",
    "\n",
    "ball_by_ball_df  = spark.read.schema(ball_by_ball_schema).format(\"csv\").option(\"header\",\"true\").option(\"dateFormat\",'M/d/yyyy').load(\"s3://ipl-data-analysis-project/Ball_By_Ball.csv\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed99da4b-a957-4ecf-8062-d6e13f9e127b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "match_schema = StructType([\n",
    "    StructField(\"Match_SK\", IntegerType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"Team1\", StringType(), True),\n",
    "    StructField(\"Team2\", StringType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"Season_Year\", IntegerType(), True),\n",
    "    StructField(\"Venue_Name\", StringType(), True),\n",
    "    StructField(\"City_Name\", StringType(), True),\n",
    "    StructField(\"Country_Name\", StringType(), True),\n",
    "    StructField(\"Toss_Winner\", StringType(), True),\n",
    "    StructField(\"match_winner\", StringType(), True),\n",
    "    StructField(\"Toss_Name\", StringType(), True),\n",
    "    StructField(\"Win_Type\", StringType(), True),\n",
    "    StructField(\"Outcome_Type\", StringType(), True),\n",
    "    StructField(\"ManOfMach\", StringType(), True),\n",
    "    StructField(\"Win_Margin\", IntegerType(), True),\n",
    "    StructField(\"Country_id\", IntegerType(), True)\n",
    " \n",
    "])\n",
    "\n",
    "match_df = spark.read.schema(match_schema).format(\"csv\").option(\"header\",'true').option(\"dateFormat\", \"M/d/yyyy\").load(\"s3://ipl-data-analysis-project/Match.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd627128-4b91-4116-8ee0-6e2da7064eaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "player_schema = StructType([\n",
    "    StructField(\"Player_SK\", IntegerType(), True),\n",
    "    StructField(\"Player_Id\", IntegerType(), True),\n",
    "    StructField(\"Player_Name\", StringType(), True),\n",
    "    StructField(\"DOB\", DateType(), True),\n",
    "    StructField(\"Batting_hand\", StringType(), True),\n",
    "    StructField(\"Bowling_skill\", StringType(), True),\n",
    "    StructField(\"Country_Name\", StringType(), True)\n",
    "])\n",
    "\n",
    "player_df = spark.read.schema(player_schema).format(\"csv\").option(\"header\",'true').option(\"DateFormat\",'m/d/yyyy').load(\"s3://ipl-data-analysis-project/Player.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc6008a-37d7-4554-8836-86ac928fb6d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_match_schema = StructType([\n",
    "\n",
    "    StructField(\"Player_match_SK\", IntegerType(), True),\n",
    "    StructField(\"PlayerMatch_key\", LongType(), True),\n",
    "    StructField(\"Match_Id\", IntegerType(), True),\n",
    "    StructField(\"Player_Id\", IntegerType(), True),\n",
    "    StructField(\"Player_Name\", StringType(), True),\n",
    "    StructField(\"DOB\", DateType(), True),\n",
    "    StructField(\"Batting_hand\", StringType(), True),\n",
    "    StructField(\"Bowling_skill\", StringType(), True),\n",
    "    StructField(\"Country_Name\", StringType(), True),\n",
    "    StructField(\"Role_Desc\", StringType(), True),\n",
    "    StructField(\"Player_team\", StringType(), True),\n",
    "    StructField(\"Opposit_Team\", StringType(), True),\n",
    "    StructField(\"Season_year\", IntegerType(), True),\n",
    "    StructField(\"is_manofThematch\", IntegerType(), True),\n",
    "    StructField(\"Age_As_on_match\", IntegerType(), True),\n",
    "    StructField(\"IsPlayers_Team_won\", IntegerType(), True),\n",
    "    StructField(\"Batting_Status\", StringType(), True),\n",
    "    StructField(\"Bowling_Status\", StringType(), True),\n",
    "    StructField(\"Player_Captain\", StringType(), True),\n",
    "    StructField(\"Opposit_captain\", StringType(), True),\n",
    "    StructField(\"Player_keeper\", StringType(), True),\n",
    "    StructField(\"Opposit_keeper\", StringType(), True),\n",
    "\n",
    "])\n",
    "\n",
    "player_match_df = spark.read.schema(player_match_schema).format(\"csv\").option(\"header\",'true').option(\"dateFormat\", \"M/d/yyyy\").load(\"s3://ipl-data-analysis-project/Player_match.csv\")\n",
    "# display(player_match_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2251d740-d30f-4680-82de-da9b32715eb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "team_schema = StructType([\n",
    "    StructField(\"team_sk\",IntegerType(),True),\n",
    "    StructField(\"team_id\",IntegerType(),True),\n",
    "    StructField(\"team_name\",StringType(),True)\n",
    "\n",
    "])\n",
    "\n",
    "team_df =  spark.read.schema(team_schema).format(\"csv\").option(\"header\",'true').load(\"s3://ipl-data-analysis-project/Team.csv\")\n",
    "# display(team_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5b5e693-6420-48a5-a739-f9ab57559c7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#filter to include only valid deliveries (excluding extras like wides and no balls for specific analysis)\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.filter((col(\"Wides\") == 0 ) & (col(\"Noballs\") == 0))\n",
    "\n",
    "\n",
    "# aggregation:  Calucalte the total and average runs scored in each match and inning\n",
    "\n",
    "total_and_avg_runs = ball_by_ball_df.groupBy(\"MatcH_id\",\"Innings_No\").agg(\n",
    "    sum(\"Runs_Scored\").alias(\"total_runs\"),\n",
    "    avg(\"Runs_Scored\").alias(\"average_runs\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21dff077-594f-47b6-aa3b-897e679dcde5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# window functions : Calucalte running total of runs in each match for each over \n",
    "\n",
    "windowSpec = Window.partitionBy(\"match_id\",\"innings_no\").orderBy(\"over_id\")\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\n",
    "    \"running_total_runs\",\n",
    "    sum(\"runs_scored\").over(windowSpec)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78edf326-b487-4154-a644-7aee86e4b3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Conditional coloumn : Flag for high impact balls (either a wicket or more than six runs including extras )\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\n",
    "    \"high_impact\",\n",
    "    when((col(\"Runs_Scored\") + col(\"Extra_Runs\") > 6) | (col(\"Bowler_Wicket\") == True ),True).otherwise(False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef2ca893-eaf5-4b7e-85d2-a7423af72457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import year, month, dayofmonth, when\n",
    "\n",
    "# Extracting year,month,day of month from the match date for more detailed time based analysis\n",
    "\n",
    "match_df = match_df.withColumn(\"year\",year(\"match_date\"))\n",
    "match_df = match_df.withColumn(\"month\",month(\"match_date\"))\n",
    "match_df = match_df.withColumn(\"day\",dayofmonth(\"match_date\"))\n",
    "\n",
    "# High Margin Win : Categorizing win margin into High, Medium , Low \n",
    "match_df = match_df.withColumn(\n",
    "    \"Win_Margin_Category\",\n",
    "    when(col(\"Win_Margin\") >= 100,\"High\")\n",
    "    .when((col(\"Win_Margin\") > 50) & (col(\"Win_Margin\") < 100),\"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "# Analyze the impact of the toss . Who wins the toss and the match \n",
    "match_df = match_df.withColumn(\n",
    "    \"Toss_and_Match_Winner\",\n",
    "    when(col(\"Toss_Winner\") == col(\"match_winner\"),\"Win\")\n",
    "    .otherwise(\"Loss\") \n",
    "  )\n",
    "display(match_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88240eeb-a19f-45fb-b28a-6c88bb0d583e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import lower,regexp_replace\n",
    "\n",
    "# Normalize and clean players names \n",
    "player_df = player_df.withColumn(\n",
    "    \"player_name_new\",\n",
    "    lower(regexp_replace(\"player_name\",\"[^a-zA-Z0-9 ]\",\"\")))\n",
    "\n",
    "# Handling missing values in batting_hand and bowling skill with the default 'unknown'\n",
    "\n",
    "player_df = player_df.na.fill({\"Batting_hand\":\"unknown\",\"Bowling_skill\":\"unknown\"})\n",
    "\n",
    "# categorizing players based on their batting hand \n",
    "\n",
    "player_df = player_df.withColumn(\n",
    "    \"Batting_Style\",\n",
    "    when(col(\"Batting_hand\").contains(\"Left\"),\"Left Handed\").otherwise(\"Right Handed\")\n",
    ")\n",
    "# display(player_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08750955-f9ee-46a1-8a4a-86d9c97c71b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col,when,current_date,expr\n",
    "\n",
    "# Add a veteren status coloumn based on player age \n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"veteran_status\",\n",
    "    when(col(\"Age_As_on_match\") >= 35,\"Veteran\").otherwise(\"Non-Veteran\")\n",
    ")\n",
    "\n",
    "# dynamic column to calucalte years since debut \n",
    "\n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"years_since_debut\",\n",
    "    (year(current_date()) - col(\"Season_year\"))\n",
    "\n",
    ")\n",
    "display(player_match_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb3d3682-15e5-46b7-af54-15bc4b406ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ball_by_ball_df.createOrReplaceTempView(\"ball_by_ball\")\n",
    "match_df.createOrReplaceTempView(\"match\")\n",
    "player_df.createOrReplaceTempView(\"player\")\n",
    "player_match_df.createOrReplaceTempView(\"player_match\")\n",
    "team_df.createOrReplaceTempView(\"team\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e573e76b-3136-46c4-8cba-694ac2a051a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Team Dimention Table \n",
    "spark.sql(\"\"\"\n",
    "          Create or Replace Temp View dim_team AS \n",
    "          SELECT DISTINCT \n",
    "          team_sk,\n",
    "          team_id,\n",
    "          team_name\n",
    "          from team\n",
    "          \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e455e94-a22f-4604-83bb-244296e57880",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Player Dimention Table \n",
    "spark.sql(\"\"\"\n",
    "          Create or Replace Temp View dim_player AS \n",
    "          SELECT DISTINCT \n",
    "          p.player_sk,\n",
    "          p.player_id,\n",
    "          p.player_name,\n",
    "          p.dob,\n",
    "          p.batting_hand,\n",
    "          p.bowling_skill,\n",
    "          pm.Role_Desc,\n",
    "          pm.Season_year,\n",
    "          pm.is_manofThematch,\n",
    "          pm.Age_As_on_match,\n",
    "          pm.IsPlayers_Team_won\n",
    "          FROM player p LEFT JOIN player_match pm \n",
    "          ON p.player_id = pm.player_id\n",
    "          \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff65fc85-bd19-4a67-b000-e09185048c43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Date Dimention \n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW dim_date AS \n",
    "SELECT DISTINCT \n",
    "        CAST(DATE_FORMAT(match_date,'yyyyMMdd') AS INT) AS date_sk,\n",
    "        match_date,\n",
    "        DAY(match_date) as day,\n",
    "        MONTH(match_date) as month,\n",
    "        QUARTER(match_date) as quarter,\n",
    "        YEAR(match_date) as year,\n",
    "        DAYOFWEEK(match_date) as weekday\n",
    "        FROM match\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e129dd92-b57b-4db4-aac6-e4747eb0d0fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Match Dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a628637-1e9b-44d1-9336-e0e6e121db54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dd = spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW dim_match AS \n",
    "    SELECT DISTINCT \n",
    "    m.match_sk,\n",
    "    m.match_id,\n",
    "    t1.team_sk AS team1_sk,\n",
    "    t2.team_sk AS team2_sk,\n",
    "    dd.date_sk AS match_date_sk,\n",
    "    m.Venue_Name,\n",
    "    m.City_Name,\n",
    "    m.Country_Name,\n",
    "    tw.team_sk AS toss_winner_sk,\n",
    "    mw.team_sk AS match_winner_sk,\n",
    "    m.Toss_Winner,\n",
    "    m.match_winner,\n",
    "    m.Toss_Name,\n",
    "    m.Win_Type,\n",
    "    m.Outcome_Type,\n",
    "    p.player_sk as Man_of_match_sk,\n",
    "    m.Win_Margin,\n",
    "    m.country_id\n",
    "    FROM match m\n",
    "    LEFT JOIN team t1 ON m.Team1 = t1.team_id\n",
    "    LEFT JOIN team t2 ON m.Team2 = t2.team_id\n",
    "    LEFT JOIN team tw ON m.Toss_Winner = tw.team_id\n",
    "    LEFT JOIN team mw ON m.match_winner = mw.team_id\n",
    "    LEFT JOIN player p ON m.ManOfMach = p.player_id\n",
    "    LEFT JOIN dim_date dd ON m.match_date = dd.match_date\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "dd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1118ca1e-1427-4458-a331-65353c7b5f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact Table Ball By Ball \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW fact_ball_by_ball AS \n",
    "SELECT \n",
    "ROW_NUMBER() OVER(ORDER BY b.match_id,b.innings_no,b.over_id,b.ball_id) AS ball_sk,\n",
    "m.match_sk,\n",
    "b.innings_no,\n",
    "b.over_id,\n",
    "b.ball_id,\n",
    "sp.player_sk AS striker_sk,\n",
    "nsp.player_sk AS non_striker_sk,\n",
    "bp.player_sk AS bowler_sk,\n",
    "bt.team_sk AS batting_team_sk,\n",
    "bwt.team_sk AS bowling_team_sk,\n",
    "b.Bowler_Wicket,\n",
    "b.runs_scored,\n",
    "b.extra_runs,\n",
    "b.wides,\n",
    "b.legbyes,\n",
    "b.byes,\n",
    "b.noballs,\n",
    "b.penalty,\n",
    "CASE WHEN b.out_type IS NOT NULL THEN 1 ELSE 0 END AS wicket_flag,\n",
    "b.out_type,\n",
    "b.caught,\n",
    "b.bowled,\n",
    "b.run_out,\n",
    "b.lbw,\n",
    "b.retired_hurt,\n",
    "b.stumped,\n",
    "b.caught_and_bowled,\n",
    "b.hit_wicket,\n",
    "dd.date_sk AS match_date_sk \n",
    "FROM ball_by_ball b\n",
    "LEFT JOIN match m ON b.match_id = m.match_id\n",
    "LEFT JOIN player sp ON b.StrikerSK = sp.player_id\n",
    "LEFT JOIN player nsp ON b.NonStriker_SK = nsp.player_id\n",
    "LEFT JOIN player bp ON b.BOWLER_SK = bp.player_id\n",
    "LEFT JOIN team bt ON b.battingTeam_SK = bt.team_sk\n",
    "LEFT JOIN team bwt ON b.BowlingTeam_SK = bwt.team_sk\n",
    "LEFT JOIN dim_date dd ON m.match_date = dd.match_date         \n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73bcf199-2b41-448c-931c-6be3589a05bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "top_scoring_batsman_per_season = spark.sql(\"\"\"\n",
    "Select p.Player_Name,p.Season_year,SUM(b.Runs_Scored) as total_runs FROM fact_ball_by_ball b \n",
    "join dim_player p ON b.striker_sk = p.player_sk\n",
    "GROUP BY p.Player_Name,p.Season_year\n",
    "ORDER BY p.Season_year,total_runs DESC\n",
    "                                           \n",
    "                                           \"\"\")\n",
    "\n",
    "top_scoring_batsman_per_season.show(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "def281dd-bdd7-4ae1-a1dc-d56d3a74acd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "553f6f08-8940-462b-a164-57a68cf7dc6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "economical_bowlers_powerplay = spark.sql(\"\"\"\n",
    "SELECT p.player_name,\n",
    "AVG(b.runs_scored) AS avg_runs_per_ball,\n",
    "COUNT(b.bowler_wicket) AS total_wickets FROM fact_ball_by_ball b \n",
    "JOIN dim_player p ON b.bowler_sk = p.player_sk\n",
    "Where b.over_id <= 6 \n",
    "GROUP BY p.player_name\n",
    "HAVING COUNT(*) > 10\n",
    "Order BY avg_runs_per_ball,total_wickets DESC\n",
    "\"\"\")\n",
    "economical_bowlers_powerplay.show(n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fdee6f3-0d24-4374-a9bb-91b9bfb0a186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "toss_impact_on_individual_matches = spark.sql(\"\"\"\n",
    "         SELECT m.match_id,m.toss_winner,m.toss_name,m.match_winner,\n",
    "         CASE When m.toss_winner = m.match_winner THEN \"Win\" ELSE \"Loss\" END as Match_OUTCOME\n",
    "         FROM match m  \n",
    "         WHERE m.toss_name IS NOT NULL\n",
    "         ORDER BY m.match_id                                    \n",
    "           \"\"\")\n",
    "\n",
    "# display(toss_impact_on_individual_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daf20e86-4942-4231-a361-ac236bdcf51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "average_runs_in_wins = spark.sql(\"\"\"\n",
    "SELECT p.player_name,AVG(b.runs_scored) as avg_runs_in_wins,COUNT(*) as innings_played\n",
    "from ball_by_ball b\n",
    "JOIN player_match pm ON b.match_id = pm.match_id AND b.striker = pm.player_id\n",
    "JOIN player p ON pm.player_id = p.player_id\n",
    "JOIN match m ON pm.match_id = m.match_id\n",
    "WHERE m.match_winner = pm.player_team\n",
    "GROUP BY p.player_name\n",
    "ORDER BY avg_runs_in_wins DESC                                 \n",
    "\"\"\")\n",
    "\n",
    "# average_runs_in_wins.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4052274-227c-4288-be2e-328ffb29fa39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "economical_bowlers_pd = economical_bowlers_powerplay.toPandas()\n",
    "\n",
    "\n",
    "# Visualization using MatPlotLib\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Limiting to top 10 for clarity of the plot \n",
    "\n",
    "top_economical_bowlers = economical_bowlers_pd.nsmallest(10,'avg_runs_per_ball')\n",
    "plt.bar(top_economical_bowlers['player_name'],top_economical_bowlers['avg_runs_per_ball'],color='skyblue')\n",
    "plt.xlabel('Bowler Name')\n",
    "plt.ylabel('Average Runs Per Ball')\n",
    "plt.title('Most Economical Bowlers in Powerplay Overs (Top 10)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d07d18b-016c-43d5-8141-1367b1e5f49e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns \n",
    "\n",
    "# converting a dataframe in to pandas \n",
    "\n",
    "toss_impact_pd = toss_impact_on_individual_matches.toPandas()\n",
    "# Creating a Count Plot to show win / loss after winning toss\n",
    "\n",
    "# Visualization using MatPlotLib\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='toss_winner',hue='Match_OUTCOME',data=toss_impact_pd)\n",
    "plt.xlabel('Toss Winner')\n",
    "plt.ylabel('No Of Matches')\n",
    "plt.title('Impact of Winning Toss on Match Outcome')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cafdcb4-6a7a-4ae7-97d9-1dcfb25774ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "average_runs_pd = average_runs_in_wins.toPandas()\n",
    "\n",
    "# using seaboarn to plot every runs in winning matches \n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Limiting to top 10 for clarity of the plot \n",
    "\n",
    "top_scorers = average_runs_pd.nlargest(10,'avg_runs_in_wins')\n",
    "sns.barplot(x='player_name',y = 'avg_runs_in_wins',data=top_scorers)\n",
    "plt.title('Average Runs Scored by Batsman in Winning Matches (Top 10 Scorers)')\n",
    "plt.xlabel('Player Name')\n",
    "plt.ylabel('Average Runs In Wins')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "502bd105-2592-4343-a069-a3d5b696fd70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Excecute sql query\n",
    "\n",
    "scores_by_venue = spark.sql(\"\"\"\n",
    "SELECT venue_name,AVG(total_runs) AS average_score, MAX(total_runs) as Highest_score\n",
    "FROM (\n",
    "    SELECT ball_by_ball.match_id,match.venue_name,SUM(runs_scored) as total_runs\n",
    "    FROM ball_by_ball\n",
    "    JOIN match ON ball_by_ball.match_id = match.match_id\n",
    "    GROUP BY ball_by_ball.match_id,match.venue_name \n",
    ")\n",
    "GROUP BY venue_name\n",
    "ORDER BY average_score DESC\n",
    "                            \"\"\")\n",
    "\n",
    "scores_by_venue.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bdace98-8094-48e4-b084-40de310b6d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "scores_by_venue_pd = scores_by_venue.toPandas()\n",
    "\n",
    "# Visualization using MatPlotLib\n",
    "plt.figure(figsize=(14,8))\n",
    "sns.barplot(x='average_score',y = 'venue_name' ,data= scores_by_venue_pd)\n",
    "plt.title('Distribution of Scores By Venue')\n",
    "plt.xlabel('Average Score')\n",
    "plt.ylabel('Venue')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8875435-a600-49b5-98ca-6964966015ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Excecute SQL query \n",
    "dismissal_types = spark.sql(\"\"\"\n",
    "SELECT out_type,COUNT(*) AS frequency\n",
    "FROM ball_by_ball WHERE out_type IS NOT NULL\n",
    "GROUP BY out_type\n",
    "Order BY frequency DESC\n",
    "                            \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7d6c904-8918-470b-9c12-e5df927d6795",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dismissal_types_pd = dismissal_types.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='frequency',y='out_type',data=dismissal_types_pd,palette='pastel')\n",
    "plt.title('Most Frequent Dismissal Types')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Dismissal Type')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cff166d9-58a9-435d-873f-43f3443cacf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute SQL query \n",
    "\n",
    "team_toss_win_performance = spark.sql(\"\"\"\n",
    "SELECT team1, COUNT(*) AS matches_played,SUM(CASE WHEN toss_winner = match_winner THEN 1 ELSE 0 END ) AS wins_after_toss\n",
    "FROM match \n",
    "where toss_winner = team1\n",
    "GROUP BY team1\n",
    "ORDER BY wins_after_toss DESC\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7747e118-8fcc-43e3-816a-a4ebd24f8fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "team_toss_win_pd = team_toss_win_performance.toPandas()\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='wins_after_toss',y='team1',data=team_toss_win_pd)\n",
    "plt.title('Team Performance After Winning Toss')\n",
    "plt.xlabel('Wins After Winning Toss')\n",
    "plt.ylabel('Team')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f885ce-51a4-454e-8bad-01e44e8318e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# How Many Matches Were Played In Each IPL Season \n",
    "# display(match_df)\n",
    "\n",
    "matches_played_in_each_ipl_season = spark.sql(\"\"\"\n",
    "    SELECT Season_Year,Count(*) as Total_Matches_played_in_each_season FROM match GROUP BY Season_Year ORDER BY Season_Year                                        \n",
    "                                            \"\"\")\n",
    "\n",
    "matches_played_in_each_ipl_season.show(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fff0ab1-5f47-4f1a-beb2-f266b8a1f220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "matches_played_in_each_ipl_season_pd = matches_played_in_each_ipl_season.toPandas()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='Season_Year',y='Total_Matches_played_in_each_season',data=matches_played_in_each_ipl_season_pd,color='red')\n",
    "plt.title('Total Matches Played In Each IPL Season')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Total Matches Played')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae8bc1aa-33f4-4809-b7cc-fd2530324af8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Which teams have won the most matches overall?\n",
    "\n",
    "# team_won_the_most_matches = spark.sql(\"\"\"\n",
    "# SELECT COUNT(*) as Wins_total, match_winner FROM match GROUP BY match_winner ORDER BY Wins_total DESC limit 1\n",
    "#                                       \"\"\")\n",
    "\n",
    "team_won_the_most_matches = match_df.groupBy('match_winner').count().withColumnRenamed('count', 'Wins_total').orderBy('Wins_total', ascending=False).limit(1)\n",
    "\n",
    "display(team_won_the_most_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f748520-4038-457a-8c0d-684b69f30107",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759839491522}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "IPL Data Analysis Project 1 PySpark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
